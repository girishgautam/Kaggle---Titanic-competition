{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /kaggle/input/titanic/train.csv does not exist: '/kaggle/input/titanic/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-268c7fea3e09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/kaggle/input/titanic/train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/kaggle/input/titanic/test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File /kaggle/input/titanic/train.csv does not exist: '/kaggle/input/titanic/train.csv'"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = train_df.copy()\n",
    "test_df1 = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Ticket and Cabin columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = train_df1.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_df1 = test_df1.drop(['Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Create Title coumn from Name column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(name):\n",
    "    title = re.search('([A-Za-z]+)\\.', name)\n",
    "    return title[1]\n",
    "\n",
    "train_df1['Title'] = train_df1['Name'].apply(extract)\n",
    "test_df1['Title'] = test_df1['Name'].apply(extract) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Dr': 0, 'Rev': 0, 'Mlle': 2, 'Col': 0, 'Major': 0,\n",
    "             'Mme': 2, 'Sir': 0, 'Jonkheer': 0, 'Capt': 0, 'Ms': 2, 'Countess': 2, 'Lady': 1, 'Don': 0}\n",
    "\n",
    "train_df1['Title'] = train_df1['Title'].map(dict)\n",
    "test_df1['Title'] = test_df1['Title'].map(dict)\n",
    "\n",
    "test_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = train_df1.drop(['Name', 'PassengerId'], axis=1)\n",
    "test_df1 = test_df1.drop(['Name'], axis=1)\n",
    "test_df1['Title'].fillna(2, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sex - convert to numeric value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['Sex'] = test_df1['Sex'].apply(lambda x: 0 if x=='male' else 1)\n",
    "train_df1['Sex'] = train_df1['Sex'].apply(lambda x: 0 if x=='male' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age - Fill missing values- median values by grouping('Sex', 'Pclass', 'Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['Age'].fillna(train_df1.groupby(['Sex', 'Pclass'])['Age'].transform('median'), inplace=True)\n",
    "test_df1['Age'].fillna(test_df1.groupby(['Sex', 'Pclass'])['Age'].transform('median'), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace age with age bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine = [train_df1, test_df1]\n",
    "\n",
    "# train_df1['AgeBand'] = pd.cut(train_df1['Age'], 5)\n",
    "# test_df1['AgeBand'] = pd.cut(test_df1['Age'], 5)\n",
    "\n",
    "# train_df1['Age2'] = train_df1['Age']\n",
    "# test_df1['Age2'] = test_df1['Age']\n",
    "\n",
    "# train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset in combine:    \n",
    "#     dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "#     dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "#     dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "#     dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "#     dataset.loc[ dataset['Age'] > 64, 'Age']\n",
    "\n",
    "# test_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df1 = train_df1.drop(['AgeBand'], axis=1)\n",
    "# test_df1 = test_df1.drop(['AgeBand'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Embarked - fill and convert to numeric value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find frequent value in Embarked\n",
    "freq_port1 = train_df1.Embarked.value_counts(ascending=False).index[0]\n",
    "freq_port2 = test_df1.Embarked.value_counts(ascending=False).index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['Embarked'] = train_df1['Embarked'].fillna(freq_port1)\n",
    "test_df1['Embarked'] = test_df1['Embarked'].fillna(freq_port2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['Embarked'] = train_df1['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "test_df1['Embarked'] = test_df1['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Family_size - By compining Parch ans SibSp columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['Family_size'] = train_df1['Parch'] + train_df1['SibSp'] + 1\n",
    "test_df1['Family_size'] = test_df1['Parch'] + train_df1['SibSp'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['Family_size'] = train_df1['Family_size'].apply(lambda x: 0 if x >=3 else 1)\n",
    "train_df1.drop(['Parch', 'SibSp'], axis=1, inplace=True)\n",
    "\n",
    "test_df1['Family_size'] = test_df1['Family_size'].apply(lambda x: 0 if x >=3 else 1)\n",
    "test_df1.drop(['Parch', 'SibSp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fare - Test data- fill mean value¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['FareBand'] = pd.qcut(train_df['Fare'], 10)\n",
    "train_df1['FareBand'] = train_df1['FareBand'].astype('category')\n",
    "train_df1['Fare_cat'] = train_df1['FareBand'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['FareBand'] = pd.qcut(test_df['Fare'], 10)\n",
    "test_df1['FareBand'] = test_df1['FareBand'].astype('category')\n",
    "test_df1['Fare_cat'] = test_df1['FareBand'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = train_df1.drop(['Fare', 'FareBand'], axis=1)\n",
    "test_df1 = test_df1.drop(['Fare', 'FareBand'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df1['Title'] = test_df1['Title'].apply(np.int64) # convert Title in test_df1 into integer\n",
    "# test_df1['Title'] = test_df1['Age'].apply(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1.astype(int).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1.astype(int).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model, predict and solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier,VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df1.drop(\"Survived\", axis=1)\n",
    "y = train_df1[\"Survived\"]\n",
    "X_test  = test_df1.drop(\"PassengerId\", axis=1).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=30)\n",
    "knn.fit(X_train, y_train)\n",
    "Y_pred_knn = knn.predict(X_test)\n",
    "acc_log = round(knn.score(X_valid, y_valid) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = DecisionTreeClassifier()\n",
    "dst.fit(X_train, y_train)\n",
    "Y_pred_dst = dst.predict(X_test)\n",
    "acc_log = round(dst.score(X_valid, y_valid) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(dst, random_state=7)\n",
    "\n",
    "# ada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "#               \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "#               \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n",
    "#               \"n_estimators\" :[1,2],\n",
    "#               \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\n",
    "\n",
    "ada_param_best = {\"base_estimator__criterion\" : [\"entropy\"],\n",
    "              \"base_estimator__splitter\" :   [\"random\"],\n",
    "              \"algorithm\" : ['SAMME.R'],\n",
    "              \"n_estimators\" :[2],\n",
    "              \"learning_rate\":  [0.1]}\n",
    "\n",
    "gs_ada = GridSearchCV(ada,param_grid = ada_param_best, cv=k_fold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gs_ada.fit(X_train, y_train)\n",
    "\n",
    "# best_param = gs_ada.best_params_\n",
    "\n",
    "Y_pred_ada = gs_ada.predict(X_test)\n",
    "\n",
    "acc_log = round(gs_ada.score(X_valid, y_valid) * 100, 2)\n",
    "\n",
    "ada_best = gs_ada.best_estimator_\n",
    "\n",
    "print(acc_log)\n",
    "# print(best_param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "best_param_grid = {'n_estimators': [2000], 'min_samples_split': [10], 'min_samples_leaf': [4], 'max_features': ['auto'], 'max_depth': [50], 'bootstrap': [False]}\n",
    "\n",
    "gs_rfc = GridSearchCV(rfc,param_grid = best_param_grid, cv=k_fold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "gs_rfc.fit(X_train, y_train)\n",
    "\n",
    "Y_pred_rfc = gs_rfc.predict(X_test)\n",
    "acc_log = round(gs_rfc.score(X_valid, y_valid) * 100, 2)\n",
    "\n",
    "rfc_best = gs_rfc.best_estimator_\n",
    "\n",
    "\n",
    "print(acc_log)\n",
    "# print(gs_rfc.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs = GaussianNB()\n",
    "nbs.fit(X_train, y_train)\n",
    "Y_pred_nbs = nbs.predict(X_test)\n",
    "acc_log = round(nbs.score(X_valid, y_valid) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(probability=True)\n",
    "\n",
    "# svc_param_grid = {'kernel': ['rbf'], \n",
    "#                   'gamma': [ 0.01, 0.1, 1,10],\n",
    "#                  'C': [1, 10, 50, 100,200,300, 1000]}\n",
    "\n",
    "best_param = {'kernel': ['rbf'], \n",
    "                  'gamma': [ 0.01],\n",
    "                 'C': [50]}\n",
    "\n",
    "gs_svc = GridSearchCV(svc,param_grid = best_param, cv=k_fold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "gs_svc.fit(X_train, y_train)\n",
    "\n",
    "Y_pred_svc = gs_svc.predict(X_test)\n",
    "acc_log = round(gs_svc.score(X_valid, y_valid) * 100, 2)\n",
    "\n",
    "svc_best = gs_svc.best_estimator_\n",
    "\n",
    "\n",
    "print(acc_log)\n",
    "# print(gs_svc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression(max_iter=200)\n",
    "lgr.fit(X_train, y_train)\n",
    "Y_pred_lgr = lgr.predict(X_test)\n",
    "acc_log = round(lgr.score(X_valid, y_valid) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_estimators=1000, learning_rate=0.1)\n",
    "\n",
    "# params = {\n",
    "#         'min_child_weight': [1, 5, 10],\n",
    "#         'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "#         'subsample': [0.6, 0.8, 1.0],\n",
    "#         'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "#         'max_depth': [3, 4, 5]\n",
    "#         }\n",
    "params_best = {\n",
    "        'min_child_weight': [5],\n",
    "        'gamma': [1],\n",
    "        'subsample': [1.0],\n",
    "        'colsample_bytree': [0.8],\n",
    "        'max_depth': [5]\n",
    "        }\n",
    "\n",
    "gs_xgb = GridSearchCV(xgb,param_grid=params_best, cv=k_fold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gs_xgb.fit(X_train, y_train)\n",
    "\n",
    "Y_pred_xgb = gs_xgb.predict(X_test)\n",
    "acc_log = round(gs_xgb.score(X_valid, y_valid) * 100, 2)\n",
    "\n",
    "xgb_best = gs_xgb.best_estimator_\n",
    "\n",
    "\n",
    "print(acc_log)\n",
    "# print(gs_xgb.best_params_)\n",
    "\n",
    "\n",
    "# xgb.fit(X_train, y_train)\n",
    "# Y_pred_xgb = xgb.predict(X_test)\n",
    "# acc_log = round(xgb.score(X_valid, y_valid) * 100, 2)\n",
    "# acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votingC = VotingClassifier(estimators=[('rfc', rfc_best),\n",
    "('svc', svc_best), ('adac',ada_best),('xgb',xgb_best)], voting='soft', n_jobs=4)\n",
    "\n",
    "votingC.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_c_pred = votingC.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'PassengerId': test_df[\"PassengerId\"], 'Survived': voting_c_pred})\n",
    "output.to_csv('my_submission_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('my_submission_3.csv')\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
